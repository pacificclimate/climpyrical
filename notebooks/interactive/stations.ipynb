{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pkg_resources import resource_filename\n",
    "\n",
    "from climpyrical.gridding import scale_model_obs\n",
    "from climpyrical.data import read_data\n",
    "from climpyrical.cmd.find_matched_model_vals import add_model_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load station data for processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "source": [
    "### Parameters are loaded from config_example.yml\n",
    "Example configuration from config_example.yml:\n",
    "```\n",
    "    paths:\n",
    "        preprocessed_model_path: /data/results/intermediate/preprocessed_netcdf/\n",
    "    RL50:\n",
    "        station_dv: \"RL50 (kPa)\"\n",
    "        station_path: 'data/station_inputs/Interim_snow_rain_load_LR_composite_stations_tbd_v4.csv'\n",
    "        input_model_path: 'data/model_inputs/snw_rain_CanRCM4-LE_ens35_1951-2016_max_rl50_load_ensmean.nc'\n",
    "        medians: \n",
    "            value: 0.4\n",
    "            action: \"multiply\"\n",
    "        fill_glaciers: True\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(resource_filename(\"climpyrical\", station_path), index_col=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the columns for standard names, and standardize them.\n",
    "\n",
    "This process will not catch any and all possible inputs, so refer to documentation for \n",
    "expected column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_df_columns(df):\n",
    "    if 'longitude' in df.columns:\n",
    "        df=df.rename(columns={'longitude': 'lon'})\n",
    "    if 'long' in df.columns:\n",
    "        df=df.rename(columns={'long': 'lon'})\n",
    "    if 'latitude' in df.columns:\n",
    "        df=df.rename(columns={'latitude': 'lat'})\n",
    "    if 'name' in df.columns:\n",
    "        df=df.rename(columns={'name': 'station_name'})\n",
    "    if 'Name' in df.columns:\n",
    "        df=df.rename(columns={'Name': 'station_name'})\n",
    "    if \"prov\" in df.columns:\n",
    "        df=df.rename(columns={\"prov\": \"province\"})\n",
    "    if \"elev\" in df.columns:\n",
    "        df=df.rename(columns={\"elev\": \"elev (m)\"})\n",
    "    if \"elevation (m)\" in df.columns:\n",
    "        df=df.rename(columns={\"elevation (m)\": \"elev (m)\"})\n",
    "    return df\n",
    "\n",
    "df = check_df_columns(df)\n",
    "df.head(5)\n",
    "\n",
    "if np.any(np.isnan(df[[\"lon\", \"lat\", \"elev (m)\", station_dv]].values)):\n",
    "    raise ValueError(\"NaN detected in station input file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load preprocessed model at target resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = read_data(resource_filename(\"climpyrical\", f\"{preprocessed_model_path}{name}.nc\"))\n",
    "(dv, ) = ds.data_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform unit conversion if necessary\n",
    "\n",
    "Exclude suspect RL50 values with true 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate ratios with applied correction\n",
    "# Note the ratios are calculated in K for Temperature fields\n",
    "if ds[dv].attrs[\"units\"] == \"degC\" and \"degC\" in station_dv:\n",
    "    print(\"Temperature DV detected in degC. Converitng to Kelvin\")\n",
    "    K = 273.15 # K\n",
    "    df[station_dv] += K\n",
    "    ds[dv] += K\n",
    "\n",
    "if 'RL50 (kPa)' in station_dv:\n",
    "    df = df[df[station_dv] != 0.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use matching script to find matching model values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = add_model_values(ds=ds, df=df)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group stations that land in the same index in rlat and rlon (land in the same grid cell)\n",
    "\n",
    "This means that they are in the same grid cell and need to be aggregated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_dict = {\n",
    "    station_dv: 'mean', \n",
    "    'rlat':'mean', \n",
    "    'rlon':'mean', \n",
    "    'lat': 'mean', \n",
    "    'lon': 'mean', \n",
    "    'elev (m)': 'mean',\n",
    "    'station_name': 'first',\n",
    "    'province': 'first',\n",
    "    \"model_values\": \"mean\"\n",
    "}\n",
    "\n",
    "# Province key is used for WP10 and WP50 for\n",
    "# special treatment of Atlantic/Far NW areas\n",
    "if \"province\" not in df.columns:\n",
    "    agg_dict = agg_dict.pop(\"province\")\n",
    "\n",
    "df_match = df.groupby(\n",
    "    ['irlat', 'irlon'], as_index=False\n",
    ").agg(\n",
    "    agg_dict\n",
    ")\n",
    "\n",
    "\n",
    "irlat = df_match.irlat\n",
    "irlon = df_match.irlon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that they are correlated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df_match[station_dv], df_match.model_values)\n",
    "plt.title(\"Correlation between station and models\")\n",
    "plt.xlabel('Stations')\n",
    "plt.ylabel('Model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now each station should be matched with a value grid cell value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize the model mean to match that of the station distribution\n",
    "Find a factor, $\\beta$ such that\n",
    "$$\\mu_s - \\frac{\\mu_m}{\\beta} \\approx 0$$ where $\\mu_s$ is the spatial station mean and $\\mu_m$ is the spatial model mean.\n",
    "\n",
    "$\\beta$ is simply:\n",
    "\n",
    "$$\\beta = \\frac{\\sum_i^{N_s}{M_i}}{\\sum_i^{N_s}{S_i}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio, best_tol = scale_model_obs(df_match.model_values, df_match[station_dv])\n",
    "assert not np.any(np.isnan(ratio))\n",
    "df_match = df_match.assign(ratio=ratio)\n",
    "print(\"Scaling factor:\", best_tol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_match.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert back to degC\n",
    "if ds[dv].attrs[\"units\"] == \"degC\" and \"degC\" in station_dv:\n",
    "    print(\"Converting back to degC\")\n",
    "    K = 273.15 # K\n",
    "    df_match[station_dv] -= K\n",
    "    df_match.model_values -= K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_match.to_csv(\n",
    "    resource_filename(\n",
    "        \"climpyrical\",\n",
    "        f\"{preprocessed_stations_path}{name}.csv\"\n",
    "    ), index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.all(df_match['ratio'] >= 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
